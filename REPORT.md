# Отчет о сравнении производительности REST и gRPC сервисов

**Дата проведения:** 21 января 2026 
**Версия Locust:** 2.43.1 
**Версия Python:** 3.12.6

---

## 1. Описание тестируемого приложения

### 1.1 Архитектура

Оба сервиса реализуют CRUD операции для управления глоссарием терминов, но используют разные протоколы коммуникации:

**REST Service:**

- Фреймворк: FastAPI
- Протокол: HTTP/JSON
- База данных: SQLite
- ORM: SQLAlchemy
- Порт: 8000

**gRPC Service:**

- Фреймворк: gRPC (Python)
- Протокол: gRPC/Protobuf
- База данных: SQLite
- ORM: SQLAlchemy
- Порт: 50051

Оба сервиса используют одинаковую схему базы данных и логику работы с данными, что позволяет корректно сравнивать производительность протоколов коммуникации.

### 1.2 Используемые технологии

- **Backend:** Python 3.12
- **Web Framework:** FastAPI (REST), gRPC (RPC)
- **Database:** SQLite
- **ORM:** SQLAlchemy 2.0.36
- **Testing:** Locust 2.43.1

### 1.3 База данных

- **Тип:** SQLite
- **Схема:** Таблица `terms` с полями:
  - `id` (Integer, Primary Key)
  - `keyword` (String, Unique, Indexed)
  - `description` (String)
  - `created_at` (DateTime)
  - `updated_at` (DateTime)

### 1.4 Эндпоинты/Методы

**REST API:**

- `GET /terms` - Список всех терминов
- `GET /terms/{keyword}` - Получение термина по ключевому слову
- `POST /terms` - Создание термина
- `PUT /terms/{keyword}` - Обновление термина
- `DELETE /terms/{keyword}` - Удаление термина

**gRPC Service:**

- `ListTerms` - Список всех терминов
- `GetTerm` - Получение термина по ключевому слову
- `CreateTerm` - Создание термина
- `UpdateTerm` - Обновление термина
- `DeleteTerm` - Удаление термина

### 1.5 Данные для запросов

**Создание термина:**

```json
{
  "keyword": "string (1-255 символов, уникальный)",
  "description": "string (минимум 1 символ)"
}
```

---

## 2. Настройки тестовой среды

### 2.1 Аппаратные ресурсы

Ноутбук MSI Summit E13 Flip Evo 2022

- **CPU:** 12th Gen Intel(R) Core(TM) i7-1280P (2.00 GHz) 14 ядер
- **RAM:** 16,0 ГБ LPDDR5
- **Диск:** NVMe SSD (PCIe 4.0 x4) 512 Гбайт
- **Сеть:** IEEE 802.11ax (6E)

### 2.2 Архитектура стенда

Все компоненты запущены локально на одной машине с использованием Docker:

- **REST сервис:** `localhost:8000` (Docker контейнер)
- **gRPC сервис:** `localhost:50051` (Docker контейнер)
- **Locust:** Запускается в headless режиме из хостовой системы
- **База данных:** Локальные файлы SQLite, монтируемые в контейнеры
- **Docker Compose:** Используется для оркестрации сервисов

**Особенности конфигурации:**

- SQLite работает в режиме WAL (Write-Ahead Logging) для улучшения конкурентности
- Настроены таймауты и пулы соединений для обработки высокой нагрузки
- Сервисы изолированы в отдельных контейнерах

### 2.3 Версия Locust

2.43.1

---

## 3. Тестовые сценарии

### 3.1 Сценарий 1: Sanity Check (Легкая нагрузка)

**Логика поведения пользователя:**

- 50% запросов: Получение списка терминов (GET /terms)
- 30% запросов: Получение одного термина (GET /terms/{keyword})
- 20% запросов: Создание термина (POST /terms)
- Пауза между запросами: 1-3 секунды

**Конфигурация нагрузки:**

- Пользователи: 10
- Spawn rate: 2 пользователя/сек
- Длительность: 1 минута

**Ожидания перед запуском:**

- Все запросы должны быть успешными
- Время ответа должно быть стабильным
- Отсутствие ошибок

**Фрагмент тестового кода:**

```python
@task(5)
def task_list_terms(self):
    response = self.client.get("/terms", name="List Terms")

@task(3)
def task_get_term(self):
    keyword = get_random_keyword(self.terms)
    response = self.client.get(f"/terms/{keyword}", name="Get Term")

@task(2)
def task_create_term(self):
    term_data = generate_term_data()
    response = self.client.post("/terms", json=term_data, name="Create Term")
```

### 3.2 Сценарий 2: Normal Load (Рабочая нагрузка)

**Логика поведения пользователя:**

- 50% запросов: Получение списка терминов (GET /terms)
- 30% запросов: Получение одного термина (GET /terms/{keyword})
- 20% запросов: Создание термина (POST /terms)
- Пауза между запросами: 1-3 секунды

**Конфигурация нагрузки:**

- Пользователи: 50
- Spawn rate: 5 пользователей/сек
- Длительность: 5 минут

**Ожидания перед запуском:**

- Стабильная работа при рабочей нагрузке
- Приемлемое время ответа (< 1 секунды для большинства запросов)
- Минимальное количество ошибок (< 5%)

### 3.3 Сценарий 3: Stress Test (Стресс-тест)

**Логика поведения пользователя:**

- 50% запросов: Получение списка терминов (GET /terms)
- 30% запросов: Получение одного термина (GET /terms/{keyword})
- 20% запросов: Создание термина (POST /terms)
- Пауза между запросами: 1-3 секунды

**Конфигурация нагрузки:**

- Пользователи: 200
- Spawn rate: 20 пользователей/сек
- Длительность: 3 минуты

**Ожидания перед запуском:**

- Выявление пределов производительности
- Возможное появление ошибок при превышении лимитов
- Деградация времени ответа при максимальной нагрузке

### 3.4 Сценарий 4: Stability Test (Тест на стабильность)

**Логика поведения пользователя:**

- 50% запросов: Получение списка терминов (GET /terms)
- 30% запросов: Получение одного термина (GET /terms/{keyword})
- 20% запросов: Создание термина (POST /terms)
- Пауза между запросами: 1-3 секунды

**Конфигурация нагрузки:**

- Пользователи: 100
- Spawn rate: 10 пользователей/сек
- Длительность: 30 минут

**Ожидания перед запуском:**

- Проверка стабильности работы при длительной нагрузке
- Отсутствие утечек памяти и ресурсов
- Сохранение производительности на протяжении всего теста

---

## 4. Результаты тестирования

### 4.1 Сценарий 1: Sanity Check

#### REST API

**Основные метрики:**

- RPS: 5.01 запросов/сек
- Среднее время ответа: 31.7 ms
- p95 latency: 72 ms
- p99 latency: 79 ms
- Количество ошибок: 2 (0.68% от общего числа запросов)
- Всего запросов: 293

**Детализация по типам запросов:**

- List Terms: 144 запроса, 0 ошибок, среднее время 23.8 ms, RPS 2.46
- Get Term: 81 запрос, 0 ошибок, среднее время 19.1 ms, RPS 1.39
- Create Term: 58 запросов, 2 ошибки, среднее время 64.1 ms, RPS 0.99

**Графики:**
Результаты сохранены в [rest_sanity_20260121_164337.html](./results/rest/sanity/rest_sanity_20260121_164337.html)

#### gRPC Service

**Основные метрики:**

- RPS: 5.03 запросов/сек
- Среднее время ответа: 30.2 ms
- p95 latency: 89 ms
- p99 latency: 100 ms
- Количество ошибок: 0 (0%)
- Всего запросов: 293

**Детализация по типам запросов:**

- List Terms: 131 запрос, 0 ошибок, среднее время 21.8 ms, RPS 2.25
- Get Term: 98 запросов, 0 ошибок, среднее время 20.3 ms, RPS 1.68
- Create Term: 54 запроса, 0 ошибок, среднее время 69.3 ms, RPS 0.93

**Графики:**
Результаты сохранены в [grpc_sanity_20260121_020225.html](./results/grpc/sanity/grpc_sanity_20260121_020225.html)

### 4.2 Сценарий 2: Normal Load

#### REST API

**Основные метрики:**

- RPS: 10.63 запросов/сек
- Среднее время ответа: 2568.9 ms
- p95 latency: 12000 ms
- p99 latency: 13000 ms
- Количество ошибок: 95 (2.98% от общего числа запросов)
- Всего запросов: 3187

**Детализация по типам запросов:**

- List Terms: 1552 запроса, 0 ошибок, среднее время 5156.2 ms, RPS 5.18
- Get Term: 944 запроса, 18 ошибок, среднее время 81.6 ms, RPS 3.15
- Create Term: 641 запрос, 77 ошибок, среднее время 129.6 ms, RPS 2.14

**Наблюдения:**

- Значительная деградация производительности при получении списка терминов (среднее время ответа превышает 5 секунд)
- Появление ошибок при создании и получении терминов
- Высокий p95 и p99 latency указывает на проблемы с обработкой нагрузки

**Графики:**
Результаты сохранены в [rest_normal_20260121_164443.htm](results/rest/normal/rest_normal_20260121_164443.html)

#### gRPC Service

**Основные метрики:**

- RPS: 23.81 запросов/сек
- Среднее время ответа: 29.7 ms
- p95 latency: 82 ms
- p99 latency: 110 ms
- Количество ошибок: 0 (0%)
- Всего запросов: 7110

**Детализация по типам запросов:**

- List Terms: 3578 запросов, 0 ошибок, среднее время 29.4 ms, RPS 11.98
- Get Term: 2113 запросов, 0 ошибок, среднее время 13.0 ms, RPS 7.08
- Create Term: 1369 запросов, 0 ошибок, среднее время 56.8 ms, RPS 4.58

**Наблюдения:**

- Стабильная работа при рабочей нагрузке
- Время ответа остается низким даже при увеличении нагрузки
- Отсутствие ошибок
- RPS более чем в 2 раза выше, чем у REST API

**Графики:**
Результаты сохранены в [grpc_normal_20260121_020329.html](./results/grpc/normal/grpc_normal_20260121_020329.html)

### 4.3 Сценарий 3: Stress Test

#### REST API

**Основные метрики:**

- RPS: 4.40 запросов/сек
- Среднее время ответа: 39423.2 ms (39.4 секунды)
- p95 latency: 60000 ms (60 секунд)
- p99 latency: 79000 ms (79 секунд)
- Количество ошибок: 27 (3.42% от общего числа запросов)
- Всего запросов: 790

**Детализация по типам запросов:**

- List Terms: 274 запроса, 0 ошибок, среднее время 42673.9 ms, RPS 1.52
- Get Term: 191 запрос, 7 ошибок, среднее время 28544.7 ms, RPS 1.06
- Create Term: 125 запросов, 19 ошибок, среднее время 26926.0 ms, RPS 0.70

**Наблюдения:**

- Критическая деградация производительности: среднее время ответа превышает 39 секунд
- Все типы запросов показывают экстремально высокую латентность
- Значительное количество ошибок
- RPS снизился по сравнению с Normal Load из-за длительного времени обработки запросов

**Графики:**
Результаты сохранены в [rest_stress_20260121_164951.html](results/rest/stress/rest_stress_20260121_164951.html)

#### gRPC Service

**Основные метрики:**

- RPS: 31.66 запросов/сек
- Среднее время ответа: 31.0 ms
- p95 latency: 87 ms
- p99 latency: 140 ms
- Количество ошибок: 0 (0%)
- Всего запросов: 5953

**Детализация по типам запросов:**

- List Terms: 2895 запросов, 0 ошибок, среднее время 41.2 ms, RPS 15.39
- Get Term: 1711 запросов, 0 ошибок, среднее время 8.5 ms, RPS 9.10
- Create Term: 1147 запросов, 0 ошибок, среднее время 39.3 ms, RPS 6.10

**Наблюдения:**

- Отличная производительность даже при стресс-нагрузке
- Время ответа остается стабильным и низким
- Отсутствие ошибок
- RPS в 7 раз выше, чем у REST API при стресс-тесте
- p95 и p99 latency остаются в приемлемых пределах

**Графики:**
Результаты сохранены в [grpc_stress_20260121_020834.html](results/grpc/stress/grpc_stress_20260121_020834.html)

### 4.4 Сценарий 4: Stability Test

#### REST API

**Основные метрики:**

- RPS: 1.42 запросов/сек
- Среднее время ответа: 66618.7 ms (66.6 секунд)
- p95 latency: 107000 ms (107 секунд)
- p99 latency: 145000 ms (145 секунд)
- Количество ошибок: 75 (2.93% от общего числа запросов)
- Всего запросов: 2557

**Детализация по типам запросов:**

- List Terms: 1237 запросов, 1 ошибка, среднее время 90588.2 ms, RPS 0.69
- Get Term: 709 запросов, 16 ошибок, среднее время 39302.2 ms, RPS 0.39
- Create Term: 511 запросов, 57 ошибок, среднее время 37202.8 ms, RPS 0.28

**Наблюдения:**

- Критическая деградация производительности при длительной нагрузке
- Среднее время ответа превышает минуту
- Значительное количество ошибок
- RPS значительно снизился из-за длительного времени обработки
- Признаки исчерпания ресурсов или проблем с базой данных

**Графики:**
Результаты сохранены в [rest_stability_20260121_142709.html](results/rest/stability/rest_stability_20260121_142709.html)

#### gRPC Service

**Основные метрики:**

- RPS: 17.29 запросов/сек
- Среднее время ответа: 56.8 ms
- p95 latency: 180 ms
- p99 latency: 320 ms
- Количество ошибок: 0 (0%)
- Всего запросов: 31471

**Детализация по типам запросов:**

- List Terms: 15596 запросов, 0 ошибок, среднее время 95.0 ms, RPS 8.57
- Get Term: 9442 запроса, 0 ошибок, среднее время 7.9 ms, RPS 5.19
- Create Term: 6333 запроса, 0 ошибок, среднее время 35.9 ms, RPS 3.48

**Наблюдения:**

- Стабильная работа на протяжении всего 30-минутного теста
- Время ответа остается низким и стабильным
- Отсутствие ошибок даже при длительной нагрузке
- RPS в 12 раз выше, чем у REST API
- Незначительное увеличение p95 и p99 latency по сравнению с более короткими тестами, но остается в приемлемых пределах

**Графики:**
Результаты сохранены в [grpc_stability_20260121_021152.html](results/grpc/stability/grpc_stability_20260121_021152.html)

---

## 5. Анализ результатов

### 5.1 Деградация производительности

**REST API:**

- Деградация начинается уже при 50 пользователях (Normal Load)
- Признаки деградации:
  - Резкое увеличение времени ответа для List Terms (с 23.8 ms до 5156.2 ms)
  - Появление ошибок (2.98% при Normal Load)
  - При 200 пользователях (Stress Test) среднее время ответа достигает 39.4 секунд
  - При длительной нагрузке (Stability Test) среднее время ответа превышает 66 секунд
  - RPS снижается с увеличением нагрузки из-за длительного времени обработки запросов

**gRPC Service:**

- Деградация не наблюдается вплоть до 200 пользователей
- Признаки деградации:
  - Незначительное увеличение p95 и p99 latency при Stress Test (87 ms и 140 ms соответственно)
  - При Stability Test p95 увеличивается до 180 ms, но остается в приемлемых пределах
  - Время ответа остается стабильным на всех уровнях нагрузки
  - Отсутствие ошибок на всех этапах тестирования

### 5.2 Изменение латентности при росте нагрузки

| Пользователи    | REST (среднее, ms) | REST (p95, ms) | REST (p99, ms) | gRPC (среднее, ms) | gRPC (p95, ms) | gRPC (p99, ms) |
| --------------- | ------------------ | -------------- | -------------- | ------------------ | -------------- | -------------- |
| 10 (Sanity)     | 31.7               | 72             | 79             | 30.2               | 89             | 100            |
| 50 (Normal)     | 2568.9             | 12000          | 13000          | 29.7               | 82             | 110            |
| 100 (Stability) | 66618.7            | 107000         | 145000         | 56.8               | 180            | 320            |
| 200 (Stress)    | 39423.2            | 60000          | 79000          | 31.0               | 87             | 140            |

**Анализ:**

- **REST API:** Показывает экспоненциальный рост латентности при увеличении нагрузки. При 50 пользователях среднее время ответа увеличивается в 81 раз по сравнению с Sanity тестом. При 100 пользователях (Stability) латентность достигает критических значений (66+ секунд).
- **gRPC Service:** Демонстрирует стабильную латентность на всех уровнях нагрузки. Даже при 200 пользователях среднее время ответа остается около 31 ms, что сопоставимо с Sanity тестом. При длительной нагрузке наблюдается незначительное увеличение до 56.8 ms, но это все еще в 1000+ раз быстрее, чем REST API.

### 5.3 Бутылочное горлышко

**REST API:**
Основное узкое место находится в **базе данных SQLite** и способе обработки запросов:

1. **SQLite под высокой нагрузкой:** При большом количестве одновременных запросов SQLite испытывает проблемы с блокировками, особенно при операциях чтения больших списков (List Terms). Это видно по резкому увеличению времени ответа для List Terms (с 23.8 ms до 5156.2 ms при Normal Load).

2. **HTTP overhead:** JSON сериализация/десериализация и HTTP заголовки добавляют накладные расходы, особенно заметные при большом объеме данных (List Terms возвращает весь список терминов).

3. **FastAPI обработка:** Асинхронная обработка FastAPI может быть ограничена синхронными операциями с SQLite через SQLAlchemy.

**gRPC Service:**
Бутылочное горлышко не выявлено в рамках проведенных тестов:

1. **Protobuf эффективность:** Бинарная сериализация Protobuf значительно эффективнее JSON, особенно для больших объемов данных.

2. **gRPC оптимизации:** gRPC использует HTTP/2 с мультиплексированием, что позволяет эффективно обрабатывать множество одновременных запросов.

3. **Та же БД, но лучшая производительность:** Несмотря на использование той же SQLite базы данных, gRPC сервис показывает стабильную производительность, что указывает на более эффективную обработку запросов и меньшую нагрузку на БД благодаря оптимизированному протоколу.

---

## 6. Сравнение REST и gRPC

### 6.1 Численное сравнение латентности

| Метрика                          | REST       | gRPC    | Разница (gRPC быстрее) |
| -------------------------------- | ---------- | ------- | ---------------------- |
| Среднее время ответа (sanity)    | 31.7 ms    | 30.2 ms | 1.05x                  |
| p95 (sanity)                     | 72 ms      | 89 ms   | 0.81x (REST быстрее)   |
| p99 (sanity)                     | 79 ms      | 100 ms  | 0.79x (REST быстрее)   |
| Среднее время ответа (normal)    | 2568.9 ms  | 29.7 ms | **86.5x**              |
| p95 (normal)                     | 12000 ms   | 82 ms   | **146.3x**             |
| p99 (normal)                     | 13000 ms   | 110 ms  | **118.2x**             |
| Среднее время ответа (stress)    | 39423.2 ms | 31.0 ms | **1271.4x**            |
| p95 (stress)                     | 60000 ms   | 87 ms   | **689.7x**             |
| p99 (stress)                     | 79000 ms   | 140 ms  | **564.3x**             |
| Среднее время ответа (stability) | 66618.7 ms | 56.8 ms | **1172.9x**            |
| p95 (stability)                  | 107000 ms  | 180 ms  | **594.4x**             |
| p99 (stability)                  | 145000 ms  | 320 ms  | **453.1x**             |

**Выводы:**

- При легкой нагрузке (Sanity) оба сервиса показывают сопоставимую производительность
- При увеличении нагрузки gRPC демонстрирует превосходство в 86-1271 раз по среднему времени ответа
- p95 и p99 latency у gRPC остаются в пределах 100-320 ms даже при максимальной нагрузке, в то время как REST API показывает значения от 60 до 145 секунд

### 6.2 Сравнение RPS

| Сценарий  | REST RPS | gRPC RPS | Разница (gRPC больше)         |
| --------- | -------- | -------- | ----------------------------- |
| Sanity    | 5.01     | 5.03     | 1.00x (практически одинаково) |
| Normal    | 10.63    | 23.81    | **2.24x**                     |
| Stress    | 4.40     | 31.66    | **7.20x**                     |
| Stability | 1.42     | 17.29    | **12.18x**                    |

**Выводы:**

- При легкой нагрузке оба сервиса показывают сопоставимую пропускную способность
- При Normal Load gRPC обрабатывает в 2.24 раза больше запросов в секунду
- При Stress Test gRPC показывает в 7.2 раза большую пропускную способность
- При длительной нагрузке (Stability) разница достигает 12.18 раз в пользу gRPC
- REST API показывает снижение RPS при увеличении нагрузки из-за длительного времени обработки запросов

### 6.3 Анализ overhead

**Размер сообщений:**

- **REST JSON:** Согласно результатам тестов, средний размер ответа для List Terms составляет ~71 КБ (71013 байт при Normal Load), для Get Term ~158 байт, для Create Term ~137 байт
- **gRPC Protobuf:** Размер сообщений не отображается в Locust статистике (0 байт в Average Content Size), но Protobuf обычно на 20-30% компактнее JSON благодаря бинарной сериализации

**Network overhead:**

- **REST HTTP headers:** Стандартные HTTP заголовки добавляют ~200-500 байт на запрос (зависит от количества заголовков)
- **gRPC headers:** HTTP/2 заголовки более компактные, обычно ~50-200 байт на запрос, плюс мультиплексирование позволяет переиспользовать соединение

**Сериализация:**

- **REST JSON:** Текстовая сериализация JSON требует больше CPU и памяти. При больших объемах данных (List Terms) сериализация всего списка в JSON создает значительную нагрузку
- **gRPC Protobuf:** Бинарная сериализация Protobuf значительно быстрее и эффективнее по памяти. Оптимизирована для производительности и компактности

**Выводы:**

- gRPC имеет меньший overhead благодаря бинарному формату и HTTP/2
- При больших объемах данных (List Terms) разница в overhead становится критической
- Мультиплексирование HTTP/2 в gRPC позволяет эффективнее использовать сетевые ресурсы

---

## 7. Заключение

### 7.1 Основные выводы

1. **gRPC значительно превосходит REST API по производительности** при увеличении нагрузки. При Normal Load gRPC обрабатывает в 2.24 раза больше запросов в секунду, а при Stress Test разница достигает 7.2 раза.

2. **REST API демонстрирует критическую деградацию** уже при 50 пользователях. Среднее время ответа увеличивается с 31.7 ms до 2568.9 ms (в 81 раз), а при длительной нагрузке превышает 66 секунд.

3. **gRPC сохраняет стабильную производительность** на всех уровнях нагрузки. Даже при 200 пользователях среднее время ответа остается около 31 ms, что сопоставимо с легкой нагрузкой.

4. **Основное узкое место REST API** - база данных SQLite и обработка больших объемов данных через JSON. Операция List Terms показывает наибольшую деградацию (с 23.8 ms до 5156.2 ms при Normal Load).

5. **gRPC показывает нулевой процент ошибок** на всех этапах тестирования, в то время как REST API демонстрирует 2.93-3.42% ошибок при повышенной нагрузке.

6. **При легкой нагрузке (Sanity)** оба протокола показывают сопоставимую производительность, что указывает на то, что выбор протокола должен основываться на ожидаемой нагрузке и требованиях к производительности.

### 7.2 Рекомендации по оптимизации

**REST API:**

- **Использовать пагинацию** для List Terms вместо возврата всего списка. Это значительно снизит нагрузку на сериализацию и передачу данных.
- **Перейти на PostgreSQL или другую production-ready БД** вместо SQLite для лучшей конкурентности и производительности.
- **Внедрить кэширование** (Redis) для часто запрашиваемых данных, особенно для List Terms.
- **Оптимизировать SQL запросы** - добавить индексы, использовать connection pooling более эффективно.
- **Рассмотреть асинхронную работу с БД** через async SQLAlchemy или другие async драйверы.
- **Использовать CDN или reverse proxy** для статических данных и кэширования.

**gRPC Service:**

- **Текущая производительность отличная**, но для дальнейшей оптимизации можно:
- **Внедрить кэширование** для List Terms, если данные не часто меняются.
- **Рассмотреть использование более производительной БД** (PostgreSQL) для еще большей масштабируемости.
- **Добавить мониторинг и метрики** для отслеживания производительности в production.
- **Оптимизировать размер protobuf сообщений** при необходимости (использовать optional поля, оптимизировать структуру).

### 7.3 Возможные улучшения эксперимента

1. **Использование production-ready базы данных** (PostgreSQL, MySQL) вместо SQLite для более реалистичного сравнения. SQLite имеет ограничения по конкурентности, которые могут искажать результаты.

2. **Тестирование на отдельных машинах** для сервисов и клиента, чтобы исключить влияние конкуренции за ресурсы CPU/RAM на одной машине.

3. **Мониторинг системных ресурсов** (CPU, RAM, I/O) во время тестов для более точного определения узких мест.

4. **Тестирование с различными размерами данных** - проверить производительность при разном количестве терминов в базе (100, 1000, 10000).

5. **Добавление тестов для других операций** (Update, Delete) для более полной картины производительности.

6. **Тестирование с различными размерами payload** - проверить влияние размера данных на производительность.

7. **Использование распределенной нагрузки** - запуск Locust в распределенном режиме с нескольких машин для более реалистичной нагрузки.

8. **Добавление метрик по типам ошибок** - детальный анализ причин ошибок (таймауты, 500, 409 и т.д.).

### 7.4 Ограничения проведённого тестирования

1. **Использование SQLite вместо production-ready БД:** SQLite имеет ограничения по конкурентности (особенно при записи), что может искажать результаты сравнения протоколов. В production обычно используются PostgreSQL, MySQL или другие БД с лучшей поддержкой конкурентности.

2. **Тестирование на одной машине:** Все компоненты (сервисы, БД, клиент) запущены на одной машине, что создает конкуренцию за ресурсы CPU, RAM и I/O. Это может влиять на результаты, особенно при высокой нагрузке.

3. **Отсутствие мониторинга системных ресурсов:** Не отслеживались метрики CPU, RAM, disk I/O во время тестов, что затрудняет точное определение узких мест.

4. **Локальная сеть:** Тестирование проводилось на localhost, что исключает реальные сетевые задержки и overhead, которые присутствуют в production окружении.

5. **Ограниченный набор операций:** Тестировались только List, Get и Create операции. Update и Delete операции не были включены в тесты.

6. **Фиксированный размер данных:** Тестирование проводилось с фиксированным количеством терминов (~100). Не проверялось влияние размера базы данных на производительность.

7. **Отсутствие распределенной нагрузки:** Locust запускался на одной машине. Распределенная нагрузка с нескольких машин дала бы более реалистичные результаты.

8. **Отсутствие тестирования при различных размерах payload:** Не проверялось влияние размера передаваемых данных на производительность протоколов.

---

## Приложения

### A. Графики и визуализации

Интерактивные HTML отчеты с графиками доступны в следующих файлах:

**REST API:**

- Sanity: `results/rest/sanity/rest_sanity_20260121_164337.html`
- Normal: `results/rest/normal/rest_normal_20260121_164443.html`
- Stress: `results/rest/stress/rest_stress_20260121_164951.html`
- Stability: `results/rest/stability/rest_stability_20260121_142709.html`

**gRPC Service:**

- Sanity: `results/grpc/sanity/grpc_sanity_20260121_020225.html`
- Normal: `results/grpc/normal/grpc_normal_20260121_020329.html`
- Stress: `results/grpc/stress/grpc_stress_20260121_020834.html`
- Stability: `results/grpc/stability/grpc_stability_20260121_021152.html`

Каждый HTML файл содержит:

- График RPS (Requests Per Second) в реальном времени
- График времени ответа (Response Time)
- Таблицу статистики по типам запросов
- Детальную информацию об ошибках (если есть)
- Процентили латентности (50%, 66%, 75%, 80%, 90%, 95%, 98%, 99%, 99.9%, 99.99%, 100%)

### B. Сырые данные

Все результаты тестов сохранены в папке `results/`:

**REST API:**

- [Sanity](./results/rest/sanity/rest_sanity_20260121_164337_stats.csv)
- [Normal](./results/rest/normal/rest_normal_20260121_164443_stats.csv)
- [Stress](./results/rest/stress/rest_stress_20260121_164951_stats.csv)
- [Stability](./results/rest/stability/rest_stability_20260121_142709_stats.csv)

**gRPC Service:**

- [Sanity](./results/grpc/sanity/grpc_sanity_20260121_020225_stats.csv)
- [Normal](./results/grpc/normal/grpc_normal_20260121_020329_stats.csv)
- [Stress](./results/grpc/stress/grpc_stress_20260121_020834_stats.csv)
- [Stability](./results/grpc/stability/grpc_stability_20260121_021152_stats.csv)

HTML отчеты с графиками доступны в соответствующих папках.

### C. Конфигурация тестов

Конфигурация тестовых сценариев находится в файле `config/test_scenarios.yaml`.

Тестовые скрипты Locust:

- REST API: `locustfiles/rest_user.py`
- gRPC: `locustfiles/grpc_user.py`
- Общие утилиты: `locustfiles/common.py`

Скрипты для запуска тестов:

- Одиночный тест: `scripts/run_benchmark.ps1`
- Полный набор тестов: `scripts/run_full_benchmark.ps1`

---

**Автор:** Андрей Правосудов
**Дата:** 21 января 2026
